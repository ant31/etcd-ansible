#!/bin/bash
# CA backup script - only backs up when CA files change
# Generated by Ansible - do not edit manually
#
# Usage: ca-backup-check.sh [OPTIONS]
#
# OPTIONS:
#   --help          Show this help message
#   --force         Force backup even if files haven't changed
#   --dry-run       Show what would be done without making changes
#
# Exit codes:
#   0 - Success (backup completed or skipped because no changes)
#   1 - Fatal error (backup failed)

set -euo pipefail
set -o errtrace  # Inherit ERR trap in functions

# Trap errors and exit
trap 'error_handler $? $LINENO' ERR
trap 'log "ERROR" "Script interrupted"; exit 1' INT TERM

error_handler() {
    log "ERROR" "Command failed with exit code $1 at line $2"
    log "ERROR" "Last command: ${BASH_COMMAND}"
    exit 1
}

# AWS credentials from environment (only for aws-kms method)
export AWS_ACCESS_KEY_ID="{{ aws_access_key_id | default('') }}"
export AWS_SECRET_ACCESS_KEY="{{ aws_secret_access_key | default('') }}"
export AWS_DEFAULT_REGION="{{ aws_default_region | default('us-east-1') }}"

BACKUP_DIR="{{ etcd_cluster_backup_directory }}"
STATE_FILE="/var/lib/etcd-ca-backup/last-backup-checksum"
CA_SECRETS_DIR="/etc/step-ca/secrets"
CA_CONFIG_DIR="/etc/step-ca/config"
S3_BUCKET="{{ step_ca_backup_s3_bucket }}"
S3_PREFIX="{{ step_ca_backup_s3_prefix }}"
ENCRYPTION_METHOD="{{ step_ca_backup_encryption_method }}"
KMS_KEY_ID="{{ step_ca_backup_kms_key_id }}"
BACKUP_PASSWORD="{{ step_ca_backup_password }}"
HEALTHCHECK_URL="{{ ca_backup_healthcheck_url }}"

log() {
    local level="$1"
    shift
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$level] $*"
}

# Show help
show_help() {
    sed -n '2,/^$/p' "$0" | sed 's/^# //' | sed 's/^#//'
    exit 0
}

# Parse arguments
FORCE_BACKUP=false
DRY_RUN=false
while [[ $# -gt 0 ]]; do
    case $1 in
        --help|-h)
            show_help
            ;;
        --force)
            FORCE_BACKUP=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        *)
            log "ERROR" "Unknown option: $1"
            show_help
            ;;
    esac
done

# Calculate checksum of CA files
calculate_checksum() {
    log "INFO" "Calculating checksum of CA files..."
    local checksum=$(find "$CA_SECRETS_DIR" "$CA_CONFIG_DIR" -type f -exec sha256sum {} \; | sort | sha256sum | cut -d' ' -f1)
    log "INFO" "Local CA checksum: $checksum"
    echo "$checksum"
}

# Verify file exists on S3 and get its metadata
verify_s3_file() {
    local s3_path="$1"
    log "INFO" "Checking if file exists on S3: $s3_path"
    
    if {{ bin_dir }}/aws s3api head-object \
        --bucket "$S3_BUCKET" \
        --key "$s3_path" >/dev/null 2>&1; then
        log "INFO" "File exists on S3: s3://${S3_BUCKET}/${s3_path}"
        return 0
    else
        log "WARN" "File does not exist on S3: s3://${S3_BUCKET}/${s3_path}"
        return 1
    fi
}

# Download and verify S3 file checksum
verify_s3_checksum() {
    local s3_path="$1"
    local expected_checksum="$2"
    
    log "INFO" "Downloading file from S3 for verification..."
    local temp_file="/tmp/ca-verify-$(date +%s).tar.gz"
    
    if ! {{ bin_dir }}/aws s3 cp "s3://${S3_BUCKET}/${s3_path}" "$temp_file" >/dev/null 2>&1; then
        log "ERROR" "Failed to download file from S3 for verification"
        rm -f "$temp_file"
        return 1
    fi
    
    log "INFO" "Calculating checksum of downloaded file..."
    local actual_checksum=$(sha256sum "$temp_file" | cut -d' ' -f1)
    rm -f "$temp_file"
    
    log "INFO" "Expected checksum: $expected_checksum"
    log "INFO" "S3 file checksum:  $actual_checksum"
    
    if [ "$expected_checksum" = "$actual_checksum" ]; then
        log "INFO" "✓ Checksum verification PASSED"
        return 0
    else
        log "ERROR" "✗ Checksum verification FAILED"
        return 1
    fi
}

# Backup CA files to S3 with encryption
backup_ca() {
    local timestamp=$(date +%Y-%m-%d_%H-%M-%S)
    local year=$(date +%Y)
    local month=$(date +%m)
    local temp_archive="/tmp/ca-backup-${timestamp}.tar.gz"
    local final_file=""
    local s3_suffix=""
    
    log "INFO" "Starting CA backup process..."
    log "INFO" "Timestamp: $timestamp"
    
    if [ "$DRY_RUN" = true ]; then
        log "INFO" "[DRY-RUN] Would create backup archive from /etc/step-ca/"
        return 0
    fi
    
    log "INFO" "Creating CA backup archive..."
    if ! tar czf "$temp_archive" -C / etc/step-ca/secrets etc/step-ca/config; then
        log "ERROR" "Failed to create backup archive"
        return 1
    fi
    log "INFO" "✓ Archive created: $temp_archive"
    
    # Calculate archive checksum for verification
    local archive_checksum=$(sha256sum "$temp_archive" | cut -d' ' -f1)
    log "INFO" "Archive checksum: $archive_checksum"
    
    # Encrypt based on method
    case "$ENCRYPTION_METHOD" in
        aws-kms)
            log "INFO" "Encrypting with AWS KMS (key: $KMS_KEY_ID)..."
            local encrypted_file="/tmp/ca-backup-${timestamp}.tar.gz.kms"
            if ! {{ bin_dir }}/aws kms encrypt \
                --key-id "$KMS_KEY_ID" \
                --plaintext "fileb://${temp_archive}" \
                --output text \
                --query CiphertextBlob | base64 -d > "$encrypted_file"; then
                log "ERROR" "KMS encryption failed"
                rm -f "$temp_archive"
                return 1
            fi
            log "INFO" "✓ KMS encryption completed"
            final_file="$encrypted_file"
            s3_suffix=".kms"
            ;;
            
        symmetric)
            log "INFO" "Encrypting with OpenSSL AES-256-CBC..."
            local encrypted_file="/tmp/ca-backup-${timestamp}.tar.gz.enc"
            if ! openssl enc -aes-256-cbc -salt -pbkdf2 -iter 100000 \
                -in "$temp_archive" -out "$encrypted_file" \
                -pass pass:"$BACKUP_PASSWORD"; then
                log "ERROR" "OpenSSL encryption failed"
                rm -f "$temp_archive"
                return 1
            fi
            log "INFO" "✓ OpenSSL encryption completed"
            final_file="$encrypted_file"
            s3_suffix=".enc"
            ;;
            
        none)
            log "WARN" "No encryption - uploading plain backup (not recommended for production)"
            final_file="$temp_archive"
            s3_suffix=""
            ;;
            
        *)
            log "ERROR" "Unknown encryption method: $ENCRYPTION_METHOD"
            rm -f "$temp_archive"
            return 1
            ;;
    esac
    
    # Calculate final file checksum
    local final_checksum=$(sha256sum "$final_file" | cut -d' ' -f1)
    log "INFO" "Final file checksum: $final_checksum"
    
    # Upload to S3
    local s3_path="${S3_PREFIX}/${year}/${month}/ca-backup-${timestamp}.tar.gz${s3_suffix}"
    log "INFO" "Uploading backup to S3: s3://${S3_BUCKET}/${s3_path}"
    
    if ! {{ bin_dir }}/aws s3 cp "$final_file" \
        "s3://${S3_BUCKET}/${s3_path}" \
        --metadata "backup-timestamp=${timestamp},original-checksum=${archive_checksum},encrypted-checksum=${final_checksum}"; then
        log "ERROR" "Failed to upload backup to S3"
        rm -f "$temp_archive" "$final_file"
        return 1
    fi
    log "INFO" "✓ Upload completed"
    
    # Verify upload by checking file exists
    log "INFO" "Verifying upload..."
    if ! verify_s3_file "$s3_path"; then
        log "ERROR" "Upload verification failed - file not found on S3"
        rm -f "$temp_archive" "$final_file"
        return 1
    fi
    
    # Download and verify checksum
    log "INFO" "Verifying uploaded file integrity..."
    if ! verify_s3_checksum "$s3_path" "$final_checksum"; then
        log "ERROR" "Upload verification failed - checksum mismatch"
        rm -f "$temp_archive" "$final_file"
        return 1
    fi
    log "INFO" "✓ Upload verification PASSED"
    
    # Tag as latest with metadata for easy identification
    log "INFO" "Updating 'latest' pointer..."
    if ! {{ bin_dir }}/aws s3 cp "$final_file" \
        "s3://${S3_BUCKET}/${S3_PREFIX}/latest-ca-backup.tar.gz${s3_suffix}" \
        --metadata "backup-timestamp=${timestamp},original-checksum=${archive_checksum},encrypted-checksum=${final_checksum},retention=long-term"; then
        log "WARN" "Failed to update latest pointer (non-fatal)"
    else
        log "INFO" "✓ Latest pointer updated"
    fi
    
    # Also tag the timestamped backup for long-term retention
    log "INFO" "Tagging backup for retention policy..."
    {{ bin_dir }}/aws s3api put-object-tagging \
        --bucket "$S3_BUCKET" \
        --key "$s3_path" \
        --tagging "TagSet=[{Key=Type,Value=ca-backup},{Key=Timestamp,Value=${timestamp}},{Key=Retention,Value=long-term},{Key=Latest,Value=true}]" \
        >/dev/null 2>&1 || log "WARN" "Failed to set S3 tags (non-fatal)"
    
    # Cleanup local files
    log "INFO" "Cleaning up temporary files..."
    rm -f "$temp_archive"
    if [ "$final_file" != "$temp_archive" ]; then
        rm -f "$final_file"
    fi
    log "INFO" "✓ Cleanup completed"
    
    log "INFO" "========================================" 
    log "INFO" "Backup SUCCESS: s3://${S3_BUCKET}/${s3_path}"
    log "INFO" "Archive checksum: $archive_checksum"
    log "INFO" "Encrypted checksum: $final_checksum"
    log "INFO" "========================================"
    
    return 0
}

# Check if backup exists on S3 with matching checksum
check_s3_backup_status() {
    local checksum="$1"
    local year=$(date +%Y)
    local month=$(date +%m)
    
    log "INFO" "Checking S3 for existing backup with matching checksum..."
    
    # Try to find a backup file with matching checksum in metadata
    local latest_file="${S3_PREFIX}/latest-ca-backup.tar.gz"
    case "$ENCRYPTION_METHOD" in
        aws-kms) latest_file="${latest_file}.kms" ;;
        symmetric) latest_file="${latest_file}.enc" ;;
    esac
    
    if verify_s3_file "$latest_file"; then
        log "INFO" "Latest backup found on S3, verifying checksum..."
        # Note: We can't easily verify the original checksum from encrypted file
        # So we'll be conservative and allow force backup
        return 1  # Return 1 to indicate we should backup (conservative approach)
    else
        log "INFO" "No latest backup found on S3"
        return 1
    fi
}

# Main logic
main() {
    log "INFO" "========================================"
    log "INFO" "CA Backup Script Starting"
    log "INFO" "Time: $(date '+%Y-%m-%d %H:%M:%S')"
    log "INFO" "Encryption: $ENCRYPTION_METHOD"
    log "INFO" "S3 Bucket: s3://${S3_BUCKET}/${S3_PREFIX}"
    log "INFO" "Force backup: $FORCE_BACKUP"
    log "INFO" "Dry run: $DRY_RUN"
    log "INFO" "========================================"
    
    # Calculate current checksum
    current_checksum=$(calculate_checksum)
    
    # Check if forced backup
    if [ "$FORCE_BACKUP" = true ]; then
        log "INFO" "Force backup requested, skipping change detection"
    else
        # Check local state file
        if [ -f "$STATE_FILE" ]; then
            last_checksum=$(cat "$STATE_FILE")
            log "INFO" "Last backup checksum: $last_checksum"
            
            if [ "$current_checksum" = "$last_checksum" ]; then
                log "INFO" "Local checksum unchanged since last backup"
                
                # Verify backup actually exists on S3
                if check_s3_backup_status "$current_checksum"; then
                    log "INFO" "Backup verified on S3, skipping"
                    log "INFO" "========================================"
                    log "INFO" "No backup needed (no changes detected)"
                    log "INFO" "========================================"
                    
                    # Send healthcheck ping for "no changes" status
                    if [ -n "$HEALTHCHECK_URL" ]; then
                        curl -fsS --retry 3 "${HEALTHCHECK_URL}?status=no-changes" > /dev/null 2>&1 || \
                            log "WARN" "Healthcheck ping failed"
                    fi
                    
                    return 0
                else
                    log "WARN" "Local checksum matches but S3 verification failed"
                    log "INFO" "Proceeding with backup to ensure S3 has valid copy"
                fi
            else
                log "INFO" "CA files changed (checksum mismatch)"
            fi
        else
            log "INFO" "No previous backup state found (first run)"
        fi
    fi
    
    # Perform backup
    log "INFO" "Starting backup operation..."
    if backup_ca; then
        if [ "$DRY_RUN" = false ]; then
            echo "$current_checksum" > "$STATE_FILE"
            log "INFO" "✓ State file updated with new checksum"
        fi
        
        # Send healthcheck ping for success
        if [ -n "$HEALTHCHECK_URL" ] && [ "$DRY_RUN" = false ]; then
            log "INFO" "Sending healthcheck ping..."
            if curl -fsS --retry 3 "${HEALTHCHECK_URL}?status=success" > /dev/null 2>&1; then
                log "INFO" "✓ Healthcheck ping successful"
            else
                log "WARN" "Healthcheck ping failed (non-fatal)"
            fi
        fi
        
        log "INFO" "========================================"
        log "INFO" "CA Backup Completed Successfully"
        log "INFO" "========================================"
        return 0
    else
        log "ERROR" "========================================"
        log "ERROR" "CA Backup FAILED"
        log "ERROR" "========================================"
        
        # Send healthcheck ping for failure
        if [ -n "$HEALTHCHECK_URL" ] && [ "$DRY_RUN" = false ]; then
            curl -fsS --retry 3 "${HEALTHCHECK_URL}?status=failure" > /dev/null 2>&1 || true
        fi
        
        return 1
    fi
}

# Run main with all arguments
main "$@"
