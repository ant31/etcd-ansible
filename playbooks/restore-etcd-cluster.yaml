---
# Restore etcd cluster from backup (Disaster Recovery)
# Usage: ansible-playbook -i inventory.ini playbooks/restore-etcd-cluster.yaml
#
# This follows the etcd disaster recovery procedure:
# 1. Stop ALL etcd services
# 2. Restore snapshot on ALL nodes
# 3. Start ALL etcd services together
#
# Options:
#   -e restore_ca=true                    # Also restore CA
#   -e restore_etcd_s3_file=path/to/file  # Specific backup file
#   -e restore_confirm=false              # Skip confirmation prompt
#   -e restore_bump_revision=1000000000   # Revision bump (default: 1 billion)

- name: Confirm cluster restore
  hosts: localhost
  gather_facts: no
  tasks:
    - name: Warning about cluster restore
      pause:
        prompt: |
          âš ï¸  DISASTER RECOVERY: ETCD CLUSTER RESTORE
          
          This will:
          1. Download and decrypt backup on all nodes (etcd still running)
          2. STOP all etcd services (brief downtime)
          3. REPLACE cluster data with backup (fast - local operation)
          4. RESTART cluster with new data
          
          Cluster: {{ groups['etcd'] | length }} nodes
          
          âš ï¸  Downtime minimized: Only during stop â†’ restore â†’ start
          
          Continue? (yes/no)
      register: restore_confirm_prompt
      when: restore_confirm | default(true) | bool
    
    - name: Validate confirmation
      assert:
        that:
          - not (restore_confirm | default(true) | bool) or restore_confirm_prompt.user_input == 'yes'
        fail_msg: "âŒ Cluster restore cancelled"
      when: restore_confirm | default(true) | bool

- name: Download and decrypt backup (etcd still running - minimize downtime)
  hosts: etcd
  gather_facts: yes
  vars:
    skip_initial_backup: true
  roles:
    - etcd3/facts
    - etcd3/backups/cron
  tasks:
    - name: Ensure backup tmp restore directory exists
      file:
        path: "{{ backup_tmp_dir | default('/opt/backups/tmp') }}/restore"
        state: directory
        owner: root
        group: root
        mode: 0700
      tags:
        - restore-download

    - name: Find latest etcd backup in S3
      command: >
        {{ bin_dir }}/aws s3api list-objects-v2
        --bucket {{ etcd_upload_backup.bucket }}
        --prefix {{ etcd_upload_backup.prefix | default('') }}{{ etcd_cluster_name }}/
        --query 'reverse(sort_by(Contents, &LastModified))[0].Key'
        --output text
        --no-cli-pager
      environment:
        AWS_ACCESS_KEY_ID: "{{ aws_access_key_id | default('') }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key | default('') }}"
        AWS_DEFAULT_REGION: "{{ aws_default_region | default('us-east-1') }}"
      register: latest_etcd_backup
      when: 
        - restore_etcd_s3_file | default('latest') == 'latest'
        - restore_etcd_local_file | default('') == ''
      changed_when: false
      tags:
        - restore-download

    - name: Set backup file path
      set_fact:
        etcd_backup_file_path: "{{ restore_etcd_s3_file if restore_etcd_s3_file != 'latest' else latest_etcd_backup.stdout }}"
      when: restore_etcd_local_file | default('') == ''
      tags:
        - restore-download

    - name: Detect encryption method from backup file
      set_fact:
        backup_encryption_method: >-
          {%- if etcd_backup_file_path.endswith('.kms') -%}
          aws-kms
          {%- elif etcd_backup_file_path.endswith('.enc') -%}
          symmetric
          {%- else -%}
          none
          {%- endif -%}
      when: restore_etcd_local_file | default('') == ''
      tags:
        - restore-download

    - name: Display download plan
      debug:
        msg: |
          ðŸ“¥ Downloading backup to all nodes (etcd still running)
          
          Backup: s3://{{ etcd_upload_backup.bucket }}/{{ etcd_backup_file_path }}
          Encryption: {{ backup_encryption_method }}
          Restore directory: {{ backup_tmp_dir | default('/opt/backups/tmp') }}/restore/
          Target file: {{ backup_tmp_dir | default('/opt/backups/tmp') }}/restore/etcd-restore-{{ etcd_cluster_name }}.db
          
          This happens BEFORE stopping etcd to minimize downtime.
      when: restore_etcd_local_file | default('') == ''
      run_once: true
      tags:
        - restore-download

    - name: Download etcd backup from S3 (parallel on all nodes)
      command: >
        {{ bin_dir }}/aws s3 cp
        s3://{{ etcd_upload_backup.bucket }}/{{ etcd_backup_file_path }}
        {{ backup_tmp_dir | default('/opt/backups/tmp') }}/restore/{{ etcd_backup_file_path | basename }}
      environment:
        AWS_ACCESS_KEY_ID: "{{ aws_access_key_id | default('') }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key | default('') }}"
        AWS_DEFAULT_REGION: "{{ aws_default_region | default('us-east-1') }}"
      when: restore_etcd_local_file | default('') == ''
      tags:
        - restore-download

    - name: Decrypt etcd backup using backup script (parallel on all nodes)
      command: >
        /usr/bin/python3 {{ backup_scripts_dir }}/etcd-backup.py
        --config {{ backup_scripts_dir }}/etcd-backup-config.yaml
        --decrypt
        --input {{ backup_tmp_dir | default('/opt/backups/tmp') }}/restore/{{ etcd_backup_file_path | basename }}
        --output {{ backup_tmp_dir | default('/opt/backups/tmp') }}/restore/etcd-restore-{{ etcd_cluster_name }}.db
        --encryption {{ backup_encryption_method }}
      when:
        - restore_etcd_local_file | default('') == ''
      tags:
        - restore-download

    - name: Use local snapshot file
      copy:
        src: "{{ restore_etcd_local_file }}"
        dest: "{{ backup_tmp_dir | default('/opt/backups/tmp') }}/restore/etcd-restore-{{ etcd_cluster_name }}.db"
        remote_src: yes
      when: restore_etcd_local_file | default('') != ''
      tags:
        - restore-download

    - name: Verify snapshot is ready on all nodes
      stat:
        path: "{{ backup_tmp_dir | default('/opt/backups/tmp') }}/restore/etcd-restore-{{ etcd_cluster_name }}.db"
      register: snapshot_ready
      failed_when: not snapshot_ready.stat.exists
      tags:
        - restore-download

    - name: Cleanup encrypted temp file
      file:
        path: "{{ backup_tmp_dir | default('/opt/backups/tmp') }}/restore/{{ etcd_backup_file_path | basename }}"
        state: absent
      when: etcd_backup_file_path is defined
      tags:
        - restore-download

    - name: Display download complete
      debug:
        msg: "{{ ['âœ… Backup downloaded and decrypted on all nodes', '', 'Original S3 file: ' + (etcd_backup_file_path | basename if etcd_backup_file_path is defined else 'local file'), 'Restore directory: ' + backup_tmp_dir | default('/opt/backups/tmp') + '/restore/', 'Snapshot file: ' + backup_tmp_dir | default('/opt/backups/tmp') + '/restore/etcd-restore-' + etcd_cluster_name + '.db', 'Size: ' + ((snapshot_ready.stat.size / 1024 / 1024) | round(2) | string) + ' MB', '', 'Ready for fast restore operation.', 'etcd is still running - downtime starts now.'] }}"
      run_once: true
      tags:
        - restore-download

- name: Stop all etcd services (downtime begins)
  hosts: etcd
  gather_facts: no
  roles:
    - etcd3/facts
  tasks:
    - name: Stop etcd service on all nodes
      systemd:
        name: "{{ etcd_name }}"
        state: stopped
      failed_when: false
      tags:
        - restore-stop

- name: Restore snapshot on all nodes (fast - local file operation)
  hosts: etcd
  gather_facts: yes
  roles:
    - role: etcd3/restore
      vars:
        restore_etcd_data: true
        restore_ca: "{{ restore_ca_also | default(false) | bool }}"
        restore_confirm: false  # Already confirmed above
        restore_skip_download: true  # Already downloaded above
  tags:
    - restore-data

- name: Start all etcd services (PARALLEL - required after restore)
  hosts: etcd
  gather_facts: no
  roles:
    - etcd3/facts
    - role: etcd3/cluster/install
      vars:
        etcd_action: deploy  # Use deploy action (handles both new and existing)
      tags:
        - restore-start

- name: Verify cluster health
  hosts: etcd[0]
  gather_facts: no
  roles:
    - etcd3/facts
  tasks:
    - name: Check cluster status
      command: >
        {{ bin_dir }}/etcdctl --endpoints={{ etcd_access_addresses }}
        --cert={{ etcd_cert_paths.client.cert }}
        --cacert={{ etcd_cert_paths.client.ca }}
        --key={{ etcd_cert_paths.client.key }}
        endpoint health
      environment:
        ETCDCTL_API: "3"
      register: cluster_health
      changed_when: false
      tags:
        - restore-verify
    
    - name: Display restore result
      debug:
        msg: "{{ ['âœ… CLUSTER RESTORE COMPLETE', ''] + cluster_health.stdout_lines + ['', 'All nodes restored from backup and restarted.', '', 'Important notes:', '- Revision was bumped by ' + (restore_bump_revision | default(1000000000) | string), '- All watches were invalidated (mark-compacted)', '- Old revisions are not accessible', '', 'If using Kubernetes, restart controllers to refresh caches.'] }}"
      tags:
        - restore-verify
